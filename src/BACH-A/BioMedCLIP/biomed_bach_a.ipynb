{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5045636,"sourceType":"datasetVersion","datasetId":2929186},{"sourceId":9611120,"sourceType":"datasetVersion","datasetId":5581965},{"sourceId":9657654,"sourceType":"datasetVersion","datasetId":5899911}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing Libraries** ","metadata":{"id":"exmY-abTefFW"}},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport torch\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport torch \nfrom PIL import Image\nfrom glob import glob\nfrom json import loads,dumps\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-11-07T15:25:24.239870Z","iopub.execute_input":"2024-11-07T15:25:24.240272Z","iopub.status.idle":"2024-11-07T15:25:27.985445Z","shell.execute_reply.started":"2024-11-07T15:25:24.240232Z","shell.execute_reply":"2024-11-07T15:25:27.984290Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Loading Model** ","metadata":{}},{"cell_type":"code","source":"!pip install open_clip_torch==2.23.0 transformers==4.35.2 matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T15:25:27.987498Z","iopub.execute_input":"2024-11-07T15:25:27.988061Z","iopub.status.idle":"2024-11-07T15:25:58.509101Z","shell.execute_reply.started":"2024-11-07T15:25:27.988023Z","shell.execute_reply":"2024-11-07T15:25:58.507727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from open_clip import create_model_from_pretrained, get_tokenizer # works on open-clip-torch>=2.23.0, timm>=0.9.8\n\nmodel, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\ntokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T15:25:58.511042Z","iopub.execute_input":"2024-11-07T15:25:58.511538Z","iopub.status.idle":"2024-11-07T15:26:15.161477Z","shell.execute_reply.started":"2024-11-07T15:25:58.511485Z","shell.execute_reply":"2024-11-07T15:26:15.159941Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Preparing Data** ","metadata":{}},{"cell_type":"code","source":"# Get a list of all image ids\n\ninvasive_ids = os.listdir('/kaggle/input/bach-breast-cancer-histology-images/ICIAR2018_BACH_Challenge/ICIAR2018_BACH_Challenge/Photos/Invasive')\nnormal_ids = os.listdir('/kaggle/input/bach-breast-cancer-histology-images/ICIAR2018_BACH_Challenge/ICIAR2018_BACH_Challenge/Photos/Normal')","metadata":{"execution":{"iopub.status.busy":"2024-11-07T15:26:15.164634Z","iopub.execute_input":"2024-11-07T15:26:15.165634Z","iopub.status.idle":"2024-11-07T15:26:15.249215Z","shell.execute_reply.started":"2024-11-07T15:26:15.165589Z","shell.execute_reply":"2024-11-07T15:26:15.247929Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final image IDs & labels (considering only benign & invasive classes) \n\nfinal_ids = [] \nfinal_labels = [] \n\nfinal_ids.extend(normal_ids) \nfinal_ids.extend(invasive_ids) \nfinal_labels.extend(['Normal'] * len(normal_ids)) \nfinal_labels.extend(['Invasive'] * len(invasive_ids)) \n\nprint(len(final_ids)) \nprint(len(final_labels)) ","metadata":{"execution":{"iopub.status.busy":"2024-11-07T17:00:18.212255Z","iopub.execute_input":"2024-11-07T17:00:18.212775Z","iopub.status.idle":"2024-11-07T17:00:18.221932Z","shell.execute_reply.started":"2024-11-07T17:00:18.212736Z","shell.execute_reply":"2024-11-07T17:00:18.220454Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtaining final image paths and binary labels \n\nimg_paths = [] \nimg_labels = [] \n\nfor i in range(len(final_ids)): \n    if final_ids[i].endswith('tif'): \n        # Path to the TIF file \n        img_paths.append('/kaggle/input/bach-breast-cancer-histology-images/ICIAR2018_BACH_Challenge/ICIAR2018_BACH_Challenge/Photos/' + final_labels[i] + '/' + final_ids[i]) \n        if final_labels[i] == 'Normal': \n            img_labels.append(0) \n        else: \n            img_labels.append(1) \n\nprint(len(img_paths)) \nprint(len(img_labels))","metadata":{"execution":{"iopub.status.busy":"2024-11-07T17:00:24.001493Z","iopub.execute_input":"2024-11-07T17:00:24.001952Z","iopub.status.idle":"2024-11-07T17:00:24.010982Z","shell.execute_reply.started":"2024-11-07T17:00:24.001918Z","shell.execute_reply":"2024-11-07T17:00:24.009642Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Running Model** ","metadata":{"id":"w8esg7q8hSTW"}},{"cell_type":"code","source":"str1 = 'Well-defined cell patterns with normal tissue architecture, do not invade beyond their original layer. Nuclei uniform in size, shape, with minimal atypia. Low mitotic activity with few dividing cells. Little to no stromal reaction.'\nstr2 = 'Irregular cells, disorganized arrangements, infiltrating surrounding tissues, Blurred boundaries, breaking through basement membranes. Nuclei showing pleomorphism, variations in size, shape, staining intensity, larger, irregular.Increased mitotic figures, rapid cell division. Desmoplastic (fibrous) stromal response.'\nlabels = [str1, str2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T17:00:28.771424Z","iopub.execute_input":"2024-11-07T17:00:28.772627Z","iopub.status.idle":"2024-11-07T17:00:28.777645Z","shell.execute_reply.started":"2024-11-07T17:00:28.772566Z","shell.execute_reply":"2024-11-07T17:00:28.776543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_length = 500\n\nlabels = [\n    str1,\n    str2\n]\n\npredicted_labels = [] \nmodel.eval()\n\nfor (i, img_path) in enumerate(img_paths): \n    image = Image.open(img_path)\n    image = preprocess(image)\n    texts = tokenizer([label for label in labels], context_length=context_length)\n    \n    with torch.no_grad():\n        image = image.unsqueeze(0)\n        image_features, text_features, logit_scale = model(image, texts)\n        \n        logits = (logit_scale * image_features @ text_features.t()).softmax(dim=-1)\n        pred_index = torch.argmax(logits, dim=-1).item()\n        \n        predicted_label = labels[pred_index]\n        print(f\"Primary label: {img_labels[i]}, Predicted label: {pred_index}, Logits: {logits}\")\n        i += 1\n        \n        predicted_labels.append(pred_index)","metadata":{"id":"cSoT7-9DDknR","execution":{"iopub.status.busy":"2024-11-07T17:00:59.119723Z","iopub.execute_input":"2024-11-07T17:00:59.120881Z","iopub.status.idle":"2024-11-07T17:09:29.108616Z","shell.execute_reply.started":"2024-11-07T17:00:59.120844Z","shell.execute_reply":"2024-11-07T17:09:29.107323Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nreport = classification_report(img_labels, predicted_labels) \nprint(report) \n\ncm = confusion_matrix(img_labels, predicted_labels)\n\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Invasive Carcinoma'], yticklabels=['Normal', 'Invasive Carcinoma'])\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T17:50:30.769264Z","iopub.execute_input":"2024-11-07T17:50:30.770896Z","iopub.status.idle":"2024-11-07T17:50:31.050892Z","shell.execute_reply.started":"2024-11-07T17:50:30.770808Z","shell.execute_reply":"2024-11-07T17:50:31.049586Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}